# Awesome Chart Understanding
A curated list of the recent chart understanding work.


## Table of Contents 
*  [Tasks/Resources](#tasks)
*  [Methods](#methods)



## Tasks

### Chart Question Answering 

**Factoid Questions**

- [DVQA: Understanding Data Visualizations via Question Answering](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.pdf). Kushal Kafle, Brian Price, Scott Cohen, Christopher Kanan. CVPR 2018.
- [FigureQA: An Annotated Figure Dataset for Visual Reasoning](https://arxiv.org/abs/1710.07300). Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Akos Kadar, Adam Trischler, Yoshua Bengio. ICLR 2018 Workshop. 
- [PlotQA: Reasoning over Scientific Plots](https://arxiv.org/abs/1909.00997). Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, Pratyush Kumar. WACV 2020.
- [ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning](Ahmed Masry, Xuan Long Do, Jia Qing Tan, Shafiq Joty, Enamul Hoque). ACL 2022 Findings.
- [MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models](https://arxiv.org/abs/2310.02255). Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, Jianfeng Gao. Arxiv 2023.

**Long-form Questions**  

- [OpenCQA: Open-ended Question Answering with Charts](https://aclanthology.org/2022.emnlp-main.811/). Shankar Kantharaj, Xuan Long Do, Rixie Tiffany Leong, Jia Qing Tan, Enamul Hoque, Shafiq Joty. EMNLP 2022.

### Chart Captioning (Summarization)

- [Chart-to-Text: Generating Natural Language Descriptions for Charts by Adapting the Transformer Model](https://aclanthology.org/2020.inlg-1.20/). Jason Obeid, Enamul Hoque. INLG 2020
- [Chart-to-Text: A Large-Scale Benchmark for Chart Summarization](https://aclanthology.org/2022.acl-long.277/). Shankar Kantharaj, Rixie Tiffany Leong, Xiang Lin, Ahmed Masry, Megh Thakkar, Enamul Hoque, Shafiq Joty. ACL 2022.
- [VisText: A Benchmark for Semantically Rich Chart Captioning](https://aclanthology.org/2023.acl-long.401/). Benny Tang, Angie Boggust, Arvind Satyanarayan. ACL 2023.


## Methods

### Pre-trained Vision-language Models

- [Enhanced Chart Understanding via Visual Language Pre-training on Plot Table Pairs](https://aclanthology.org/2023.findings-acl.85/). Mingyang Zhou, Yi Fung, Long Chen, Christopher Thomas, Heng Ji, Shih-Fu Chang. ACL 2023 Findings.
- [MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering](https://aclanthology.org/2023.acl-long.714/). Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Eisenschlos. ACL 2023.
- [UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning](https://aclanthology.org/2023.emnlp-main.906/). Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty. EMNLP 2023.
- [Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding](https://proceedings.mlr.press/v202/lee23g/lee23g.pdf). Kenton Lee, Mandar Joshi, Iulia Raluca Turc, Hexiang Hu, Fangyu Liu, Julian Martin Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova. ICML 2023.


### Large Vision-language Models 

**Tailored for Chart Understanding** 
- [ChartLlama: A Multimodal LLM for Chart Understanding and Generation](https://arxiv.org/abs/2311.16483). Yucheng Han, Chi Zhang, Xin Chen, Xu Yang, Zhibin Wang, Gang Yu, Bin Fu, Hanwang Zhang. Arxiv 2023.
- [MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning](https://arxiv.org/abs/2311.10774). Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, Dong Yu. Arxiv 2023.
- [ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning](https://arxiv.org/abs/2401.02384). Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, Ping Luo. Arxiv 2024.

**General**

- [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485). Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee. NeurIPS 2023.
- [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/abs/2312.11805). Gemini Team Google. Arxiv 2023.
- [GPT-4V](https://openai.com/research/gpt-4v-system-card). OpenAI. 2023.
